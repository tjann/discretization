---
title: "(Absolute) Area Between Curves of Multiple Discretization Results for One Data Set TSD Compatible"
author: "Tiffany Jann"
date: ""
output:
  html_document:
    fig_height: 3
    fig_width: 5
---
<!-- Don't edit in between this line and the one below -->
```{r include=FALSE}
## Don't delete this chunk if you are using the DataComputing package
library(DataComputing)
options(scipen=999)
```
*Source file* 
```{r, results='asis', echo=FALSE}
includeSourceDocuments("AreaBtwnCurves.Rmd")
```
<!-- Don't edit the material above this line -->

Variable inputs
```{r}
## Gold Standard Network Data
goldFile = "ADHD_Sub010fmri.csv"
isPatientData = T
```

Helper: reads and transposes data table
```{r}
read.tcsv = function(file, header=TRUE, sep=",", ...) {

  n = max(count.fields(file, sep=sep), na.rm=TRUE)
  x = readLines(file)

  .splitvar = function(x, sep, n) {
    var = unlist(strsplit(x, split=sep))
    length(var) = n
    return(var)
  }

  x = do.call(cbind, lapply(x, .splitvar, sep=sep, n=n))
  x = apply(x, 1, paste, collapse=sep) 
  out = read.csv(text=x, sep=sep, header=header)
  return(out)

}
```

Load and normalize original gold standard network
```{r}
## Note: header=FALSE if in silico data, else TRUE
gold = read.tcsv(goldFile, header=isPatientData)

#dim(gold)
#summary(gold)
#print(min(gold))
## Vertical shift
gold = gold - min(gold)
## Should be 0
#print(min(gold))
## Scaling to unit length
gold = gold / (max(gold) - min(gold))
## Normalized gold standard network
#cat("min:", min(gold), "max:", max(gold))
```

Find all applicable files w.r.t. gold standard network
```{r}
## Make sure data file follows [identifying name]fmri[other unimportant identifiers].csv
key = gsub("fmri.*\\.csv$", "", goldFile)
pattern = paste(key, "_", sep="")

## Gets files that start with [identifying name]_
allFiles = list.files(getwd(), pattern)
allFiles
```

Helper: gets all discretization results ready for evaluation
```{r}
getfile = function(file){
  discretized = read.tcsv(file)
  rownames = discretized[,1]
  discretized = na.omit(discretized[,-1])
  
  ## Ensure data uses 0 1 instead of 1 2
  if(max(discretized) > 1){
    discretized = discretized - max(discretized) + 1
  }
  return(discretized)
}
```

Load all files into vectors using helper `getfile`
```{r}
allData = as.data.frame(sapply(allFiles, getfile))
```

Helper: returns the sum of area errors in all `m - 1` time intervals for **one node**
```{r}
nodeAreas = function(node, goldNode){
  output = 0
  for(interval in 1:(nrow(node) - 1)){ ## One interval at a time
    right = interval + 1
    binSlope = node[right,] - node[interval,]
    binIntercept = node[interval,] - binSlope * interval
    rawSlope = goldNode[right,] - goldNode[interval,]
    rawIntercept = goldNode[interval,] - rawSlope * interval
    integrand <- function(x) {abs((binSlope - rawSlope) * x + (binIntercept - rawIntercept))}
    integral = integrate(Vectorize(integrand), interval, right)
    output = output + integral$value
  }
  return(output)
}
```

Helper: obtain the sum of area error in all `n` nodes for **one data set**
```{r}
diffArea = function(method, standard){
  output = 0
  method = as.data.frame(method)
  if(nrow(method) != nrow(standard)){
    method = rbind(method, rep(0.5, ncol(method)))
  }
  for(node in 1:(length(method))){ ## Apply nodeAreas to each node in this method
    output = output + nodeAreas(method[node], standard[node])
  }
  return(output)
}
```

Obtain a **vector** of each discretization method's area **error**
```{r}
## Apply diffArea to each method's data set
scores = apply(allData, 2, diffArea, standard=gold)
```

View results, best method first
```{r}
sort(scores)
```