---
title: "Least Squares of Multiple Discretization Results for One Data Set"
author: "Tiffany Jann"
date: ""
output: 
  html_document:
    fig_height: 3
    fig_width: 5
---
<!-- Don't edit in between this line and the one below -->
```{r include=FALSE, echo=FALSE}
# Don't delete this chunk if you are using the DataComputing package
library(DataComputing)
```
*Source file* 
```{r, results='asis', echo=FALSE}
includeSourceDocuments("/Users/jann/github/discretization/leastsquares.Rmd")
```
<!-- Don't edit the material above this line -->
```{r include=FALSE}
options(scipen=999)
```

Variable inputs:
```{r}
#Gold Standard Network
goldFile <- "wk2fivefmriCS100S20N3000.csv"
```

Helper: reads and transposes data table
```{r}
read.tcsv = function(file, header=TRUE, sep=",", ...) {

  n = max(count.fields(file, sep=sep), na.rm=TRUE)
  x = readLines(file)

  .splitvar = function(x, sep, n) {
    var = unlist(strsplit(x, split=sep))
    length(var) = n
    return(var)
  }

  x = do.call(cbind, lapply(x, .splitvar, sep=sep, n=n))
  x = apply(x, 1, paste, collapse=sep) 
  out = read.csv(text=x, sep=sep, header=header)
  return(out)

}
```

Load and normalize original gold standard network
```{r}
gold <- read.tcsv(goldFile, header=FALSE)
head(gold)

print(min(gold))
#Vertical shift
gold <- gold - min(gold)
#Should be 0
print(min(gold))

#Scaling to unit length
gold <- gold / (max(gold) - min(gold))

#Normalized gold standard network
head(gold)
cat("min:", min(gold), "max:", max(gold))

#Vectors for each node of gold standard network
v1 <- gold$V1
v2 <- gold$V2
v3 <- gold$V3
v4 <- gold$V4
v5 <- gold$V5
```

Find all applicable files w.r.t. gold standard network
```{r}
#Assuming we are only using data generated by MULAN
pattern <- gsub("fmri.*\\.csv$", "", goldFile)
pattern <- paste(pattern, "_", sep="")

allfiles <- list.files(getwd(), pattern)
allfiles
```

Helper: gets all discretization results ready for evaluation
```{r}
getfile <- function(file){
  discretized <- read.tcsv(file)
  rownames <- discretized[,1]
  discretized <- na.omit(discretized[,-1])
  #Ensures data uses 0 1 instead of 1 2
  if(max(discretized) != 1){
    discretized <- discretized - max(discretized) + 1
  }
  return(discretized)
}
```

Load all files using helper `getfile`
```{r}
disc <- sapply(allfiles, getfile)
```


Helper: calculates score for a discretization result
```{r}
score <- function(discretized){
  x1 <- discretized$Gene1
  x2 <- discretized$Gene2
  x3 <- discretized$Gene3
  x4 <- discretized$Gene4
  x5 <- discretized$Gene5
  totdiff <- sum(abs(x1 - v1), na.rm=TRUE) + sum(abs(x2 - v2), na.rm=TRUE) + sum(abs(x3 - v3), na.rm=TRUE) + sum(abs(x4 - v4), na.rm=TRUE) + sum(abs(x5 - v5), na.rm=TRUE)
  return(totdiff)
}
```

Apply all `disc` files to helper `score`
```{r}
scores <- sapply(as.data.frame(disc), score)
```

View results
```{r}
sort(scores, decreasing = TRUE)
```




<!-- ```{r} -->
<!-- #discretized <- lapply getfile(file) -->
<!-- discretized <- read.tcsv("wk2five_bikmeans.csv") -->
<!-- discretized <- na.omit(discretized) -->
<!-- rownames <- discretized[,1] -->
<!-- discretized <- discretized[,-1] -->
<!-- if(max(discretized) == 2){ -->
<!--   discretized <- discretized - 1 -->
<!-- } -->
<!-- head(discretized) -->

<!-- ``` -->
