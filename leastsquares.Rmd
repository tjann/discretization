---
title: "Least Squares of Multiple Discretization Results for One Data Set"
author: "Tiffany Jann"
date: ""
output: 
  html_document:
    fig_height: 3
    fig_width: 5
---
<!-- Don't edit in between this line and the one below -->
```{r include=FALSE, echo=FALSE}
# Don't delete this chunk if you are using the DataComputing package
library(DataComputing)
```
*Source file* 
```{r, results='asis', echo=FALSE}
includeSourceDocuments("/Users/jann/github/discretization/leastsquares.Rmd")
```
<!-- Don't edit the material above this line -->
```{r include=FALSE}
options(scipen=999)
```

Variable inputs:
```{r}
#Gold Standard Network
goldFile <- "wk2ADHDfmri_Sub035.csv"
```

Helper: reads and transposes data table
```{r}
#Note: default header=TRUE, which is the case when brain regions are specified
read.tcsv = function(file, header=TRUE, sep=",", ...) {

  n = max(count.fields(file, sep=sep), na.rm=TRUE)
  x = readLines(file)

  .splitvar = function(x, sep, n) {
    var = unlist(strsplit(x, split=sep))
    length(var) = n
    return(var)
  }

  x = do.call(cbind, lapply(x, .splitvar, sep=sep, n=n))
  x = apply(x, 1, paste, collapse=sep) 
  out = read.csv(text=x, sep=sep, header=header)
  return(out)

}
```

Load and normalize original gold standard network
```{r}
gold <- read.tcsv(goldFile) #input extra parameter header=FALSE if using MULAN data
head(gold)

print(min(gold))
#Vertical shift
gold <- gold - min(gold)
#Should be 0
print(min(gold))

#Scaling to unit length
gold <- gold / (max(gold) - min(gold))

#Normalized gold standard network
head(gold)
cat("min:", min(gold), "max:", max(gold))
```

Find all applicable files w.r.t. gold standard network
```{r}
#Assuming we are only using data generated by MULAN
key <- gsub("fmri.*\\.csv$", "", goldFile)
pattern <- paste(key, "_", sep="")

allfiles <- list.files(getwd(), pattern)
allfiles
```

Helper: gets all discretization results ready for evaluation
```{r}
getfile <- function(file){
  discretized <- read.tcsv(file)
  rownames <- discretized[,1]
  discretized <- na.omit(discretized[,-1])
  #Ensures data uses 0 1 instead of 1 2
  if(max(discretized) > 1){
    discretized <- discretized - max(discretized) + 1
  }
  return(discretized)
}
```

Load all files using helper `getfile`
```{r}
disc <- sapply(allfiles, getfile)
head(disc)
```

Helper: calculate aggregate error under all nodes of **one** discretization output
```{r}
score <- function(discretized){
  nodeError <- 0
  for(node in 1:length(discretized)){
    # cat(" at node #", node)
    # cat("method[node]", method[node])
    # cat("gold[node]",gold[node])
    # cat("diff", method[node] - gold[node])
    nodeError <- nodeError + sum( abs(discretized[node] - gold[node]), 1:length(discretized[node])) #this accounts for TSD
  }
  return(nodeError)
}
```

Apply all `disc` files to helper `score`
```{r, warning=FALSE}
scores <- apply(disc, 2, score)
```

View results, best method first
```{r}
sort(scores)
```

old
<!-- Helper: calculates score for a discretization result -->
<!-- ```{r} -->
<!-- score <- function(discretized){ -->
<!--   x1 <- discretized$Gene1 -->
<!--   x2 <- discretized$Gene2 -->
<!--   x3 <- discretized$Gene3 -->
<!--   x4 <- discretized$Gene4 -->
<!--   x5 <- discretized$Gene5 -->
<!--   totdiff <- sum(abs(x1 - v1), na.rm=TRUE) + sum(abs(x2 - v2), na.rm=TRUE) + sum(abs(x3 - v3), na.rm=TRUE) + sum(abs(x4 - v4), na.rm=TRUE) + sum(abs(x5 - v5), na.rm=TRUE) -->
<!--   return(totdiff) -->
<!-- } -->
<!-- ``` -->