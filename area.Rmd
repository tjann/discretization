---
title: "Area Comparison of Multiple Discretization Results for One Data Set"
author: "Tiffany Jann"
date: ""
output: 
  html_document:
    fig_height: 3
    fig_width: 5
---
<!-- Don't edit in between this line and the one below -->
```{r include=FALSE}
# Don't delete this chunk if you are using the DataComputing package
library(DataComputing)
options(scipen=999)
```
*Source file* 
```{r, results='asis', echo=FALSE}
includeSourceDocuments("/Users/jann/github/discretization/area.Rmd")
```
<!-- Don't edit the material above this line -->

Variable inputs
```{r}
#Gold Standard Network
goldFile = "forty_ninefmriCS100S20N204.csv"
```

Helper: reads and transposes data table
```{r}
#Note: header=FALSE if in silico data, else TRUE
read.tcsv = function(file, header=TRUE, sep=",", ...) {

  n = max(count.fields(file, sep=sep), na.rm=TRUE)
  x = readLines(file)

  .splitvar = function(x, sep, n) {
    var = unlist(strsplit(x, split=sep))
    length(var) = n
    return(var)
  }

  x = do.call(cbind, lapply(x, .splitvar, sep=sep, n=n))
  x = apply(x, 1, paste, collapse=sep) 
  out = read.csv(text=x, sep=sep, header=header)
  return(out)

}
```

Load and normalize original gold standard network
```{r}
gold = read.tcsv(goldFile, header=FALSE) #input extra parameter header=FALSE if using MULAN data

#A difference vector gold for TSD and Erdal's (change between time points)
intvlGold = as.data.frame(apply(gold, 2, diff))

dim(gold)
summary(gold)
print(min(gold))
#Vertical shift
gold = gold - min(gold)
#Should be 0
print(min(gold))
#Scaling to unit length
gold = gold / (max(gold) - min(gold))
#Normalized gold standard network
cat("min:", min(gold), "max:", max(gold))

dim(intvlGold)
summary(intvlGold)
print(min(intvlGold))
#Vertical shift
intvlGold = intvlGold - min(intvlGold)
#Should be 0
print(min(intvlGold))
#Scaling to unit length
intvlGold = intvlGold / (max(intvlGold) - min(intvlGold))
#Normalized gold standard network
cat("min:", min(intvlGold), "max:", max(intvlGold))
```

Find all applicable files w.r.t. gold standard network
```{r}
#Assuming we are only using data generated by MULAN
key = gsub("fmri.*\\.csv$", "", goldFile)
pattern = paste(key, "_", sep="")

allfiles = list.files(getwd(), pattern)
allfiles

pointFiles = allfiles[!grepl("tsd", allfiles) & !grepl("erdals", allfiles)]
intervalFiles = allfiles[grepl("tsd", allfiles) | grepl("erdals", allfiles)]
pointFiles
intervalFiles
```

Helper: gets all discretization results ready for evaluation
```{r}
getfile = function(file){
  discretized = read.tcsv(file)
  rownames = discretized[,1]
  discretized = na.omit(discretized[,-1])
  #Ensures data uses 0 1 instead of 1 2, 2 3, etc.
  if(max(discretized) > 1){
    discretized = discretized - max(discretized) + 1
  }
  return(discretized)
}
```

Load all files into vectors using helper `getfile`
```{r}
pointData = sapply(pointFiles, getfile)
intervalData = sapply(intervalFiles, getfile)
head(pointData)
head(intervalData)
```

Helper: calculate area under connected time points for one node
```{r}
partArea = function(node){
  output = sum(node[2:(length(node) - 1)], na.rm=TRUE) + (node[1] + node[length(node)]) / 2
  return(output)
}
```

Helper: calculating aggregate area under all nodes of **one** discretization output using `partArea`
```{r}
totArea = function(method){
  return(sum(sapply(method, partArea)))
}
```

Get the total area (`totArea`) for each discretization output
```{r}
point_allArea = apply(pointData, 2, totArea)
intvl_allArea = apply(intervalData, 2, totArea)
point_allArea
intvl_allArea
```

Calculating area under all gold nodes (execute once only)
```{r}
point_goldArea = sum(sapply(gold, partArea))
intvl_goldArea = sum(sapply(intvlGold, partArea))
point_goldArea
intvl_goldArea
```

Find absolute error for each method
```{r}
point_error = abs(point_allArea - point_goldArea)
intvl_error = abs(intvl_allArea - intvl_goldArea)
error = append(point_error, intvl_error)
```

View results, best method first
```{r}
sort(error)
```